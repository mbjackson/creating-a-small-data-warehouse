{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Programming Exercise: Create a Small Data Warehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Start Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .appName(\"Week 5 Assignment\") \\\n",
    "        .config(\"spark.sql.warehouse.dir\", \"./warehouse\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Gazetteer Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Create Unmanaged Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['secondary_schools', 'congressional_district', 'urban_areas', 'elementary_schools', 'tracts', 'places', 'counties', 'core_based_statistical_areas', 'zip_code_tabulation_areas', 'county_subdivisions', 'unified_school_districts']\n"
     ]
    }
   ],
   "source": [
    "# Define Paths to Data\n",
    "path_2017 = \"data/gazetteer/2017/\"\n",
    "path_2018 = \"data/gazetteer/2018/\"\n",
    "\n",
    "# Create Empty Arrays to Store Table Names\n",
    "tables = []\n",
    "\n",
    "# Get Tables Names in 2017 Directory (Same as 2018 Directory)\n",
    "for file in glob.glob(path_2017 + \"*.csv\"):\n",
    "    tables.append(os.path.splitext(os.path.basename(file))[0])\n",
    "\n",
    "# Show Tables\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Create New Table\n",
    "def create_new_table(table_name):\n",
    "    \n",
    "    # Load Paths for 2017 and 2018 Files\n",
    "    file_2017 = path_2017 + table_name + \".csv\"\n",
    "    file_2018 = path_2018 + table_name + \".csv\"\n",
    "    \n",
    "    # Load Data into Dataframes\n",
    "    df_2017 = spark.read.load(file_2017, format=\"csv\", sep=\",\", inferSchema=True, header=True)\n",
    "    df_2018 = spark.read.load(file_2018, format=\"csv\", sep=\",\", inferSchema=True, header=True)\n",
    "    \n",
    "    # Create a Union\n",
    "    df = df_2017.unionAll(df_2018)\n",
    "    \n",
    "    # Save Table to Warehouse\n",
    "    df.write.saveAsTable(table_name)\n",
    "    \n",
    "    # Print Number of Rows\n",
    "    print(\"Number of rows in {} table: {}\".format(table_name, df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in secondary_schools table: 974\n",
      "Number of rows in congressional_district table: 880\n",
      "Number of rows in urban_areas table: 7202\n",
      "Number of rows in elementary_schools table: 3926\n",
      "Number of rows in tracts table: 148002\n",
      "Number of rows in places table: 59151\n",
      "Number of rows in counties table: 6440\n",
      "Number of rows in core_based_statistical_areas table: 1890\n",
      "Number of rows in zip_code_tabulation_areas table: 66288\n",
      "Number of rows in county_subdivisions table: 73261\n",
      "Number of rows in unified_school_districts table: 21779\n"
     ]
    }
   ],
   "source": [
    "# Loop Through and Create New Tables in Warehouse\n",
    "for table in tables:\n",
    "    create_new_table(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secondary_schools\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     974|\n",
      "+--------+\n",
      "\n",
      "congressional_district\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     880|\n",
      "+--------+\n",
      "\n",
      "urban_areas\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    7202|\n",
      "+--------+\n",
      "\n",
      "elementary_schools\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    3926|\n",
      "+--------+\n",
      "\n",
      "tracts\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  148002|\n",
      "+--------+\n",
      "\n",
      "places\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   59151|\n",
      "+--------+\n",
      "\n",
      "counties\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    6440|\n",
      "+--------+\n",
      "\n",
      "core_based_statistical_areas\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    1890|\n",
      "+--------+\n",
      "\n",
      "zip_code_tabulation_areas\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   66288|\n",
      "+--------+\n",
      "\n",
      "county_subdivisions\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   73261|\n",
      "+--------+\n",
      "\n",
      "unified_school_districts\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   21779|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop Through and Get Count via SQL\n",
    "for table in tables:\n",
    "    print(table)\n",
    "    spark.sql(\"SELECT COUNT(*) FROM {}\".format(table)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Load and Query Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SQL Statements\n",
    "sql = \"\"\"SELECT a.state as State, a.year as Year, a.cnt Unified, b.cnt Elementary, c.cnt as Secondary \n",
    "         FROM (SELECT state, year, count(*) as cnt\n",
    "               FROM unified_school_districts\n",
    "               WHERE state IN('NE','IA')\n",
    "               GROUP BY state, year) a\n",
    "         LEFT JOIN\n",
    "           (SELECT state, year, count(*) as cnt\n",
    "            FROM elementary_schools\n",
    "            WHERE state IN('NE','IA')\n",
    "            GROUP BY state, year) b\n",
    "         ON a.state = b.state\n",
    "         AND a.year = b.year\n",
    "         LEFT JOIN\n",
    "           (SELECT state, year, count(*) as cnt\n",
    "            FROM secondary_schools\n",
    "            WHERE state IN('NE','IA')\n",
    "            GROUP BY state, year) c\n",
    "         ON a.state = c.state\n",
    "         AND a.year = c.year\n",
    "         ORDER BY a.state, a.year\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-------+----------+---------+\n",
      "|State|Year|Unified|Elementary|Secondary|\n",
      "+-----+----+-------+----------+---------+\n",
      "|   IA|2017|    336|      null|     null|\n",
      "|   IA|2018|    333|      null|     null|\n",
      "|   NE|2017|    251|      null|     null|\n",
      "|   NE|2018|    246|      null|     null|\n",
      "+-----+----+-------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Flight Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in flights table: 3606803\n",
      "Number of rows in airport_codes table: 54591\n"
     ]
    }
   ],
   "source": [
    "# Load Flight Data\n",
    "flights = spark.read.parquet(\"data/domestic-flights/flights.parquet\")\n",
    "airport_codes = spark.read.format(\"csv\").options(header=\"true\", inferSchema=\"true\").load(\"data/airport-codes/airport-codes.csv\")\n",
    "\n",
    "# Save Table to Warehouse\n",
    "flights.write.saveAsTable(\"flights\")\n",
    "airport_codes.write.saveAsTable(\"airport_codes\")\n",
    "    \n",
    "# Print Number of Rows\n",
    "print(\"Number of rows in {} table: {}\".format(\"flights\", flights.count()))\n",
    "print(\"Number of rows in {} table: {}\".format(\"airport_codes\", airport_codes.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|flight_counts|\n",
      "+-------------+\n",
      "|      3606803|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT COUNT(*) AS flight_counts FROM {}\".format(\"flights\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|airport_codes_count|\n",
      "+-------------------+\n",
      "|              54591|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT COUNT(*) AS airport_codes_count FROM {}\".format(\"airport_codes\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SQL Statement\n",
    "sql1 = \"\"\"CREATE OR REPLACE TEMPORARY VIEW flights_origin AS\n",
    "          SELECT\n",
    "            a.*,\n",
    "            b.type as origin_airport_type,\n",
    "            b.name as origin_airport_name,\n",
    "            b.elevation_ft as origin_airport_elevation_ft,\n",
    "            b.iso_region as origin_airport_region,\n",
    "            b.municipality as origin_airport_municipality,\n",
    "            b.gps_code as origin_airport_gps_code,\n",
    "            b.coordinates as origin_airport_coordinates\n",
    "          FROM flights a\n",
    "          LEFT JOIN airport_codes b\n",
    "          ON a.origin_airport_code = b.iata_code\"\"\"\n",
    "\n",
    "# Execute SQL Statement\n",
    "spark.sql(sql1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- origin_airport_code: string (nullable = true)\n",
      " |-- destination_airport_code: string (nullable = true)\n",
      " |-- origin_city: string (nullable = true)\n",
      " |-- destination_city: string (nullable = true)\n",
      " |-- passengers: long (nullable = true)\n",
      " |-- seats: long (nullable = true)\n",
      " |-- flights: long (nullable = true)\n",
      " |-- distance: double (nullable = true)\n",
      " |-- origin_population: long (nullable = true)\n",
      " |-- destination_population: long (nullable = true)\n",
      " |-- flight_year: long (nullable = true)\n",
      " |-- flight_month: long (nullable = true)\n",
      " |-- __index_level_0__: long (nullable = true)\n",
      " |-- origin_airport_type: string (nullable = true)\n",
      " |-- origin_airport_name: string (nullable = true)\n",
      " |-- origin_airport_elevation_ft: double (nullable = true)\n",
      " |-- origin_airport_region: string (nullable = true)\n",
      " |-- origin_airport_municipality: string (nullable = true)\n",
      " |-- origin_airport_gps_code: string (nullable = true)\n",
      " |-- origin_airport_coordinates: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.table('flights_origin').printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SQL Statement\n",
    "sql2 = \"\"\"CREATE OR REPLACE TEMPORARY VIEW flights_combined AS\n",
    "          SELECT\n",
    "            a.*,\n",
    "            b.type as destination_airport_type,\n",
    "            b.name as destination_airport_name,\n",
    "            b.elevation_ft as destination_airport_elevation_ft,\n",
    "            b.iso_region as destination_airport_region,\n",
    "            b.municipality as destination_airport_municipality,\n",
    "            b.gps_code as destination_airport_gps_code,\n",
    "            b.coordinates as destination_airport_coordinates\n",
    "          FROM flights_origin a\n",
    "          LEFT JOIN airport_codes b\n",
    "          ON a.origin_airport_code = b.iata_code\"\"\"\n",
    "\n",
    "# Execute SQL Statement\n",
    "spark.sql(sql2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- origin_airport_code: string (nullable = true)\n",
      " |-- destination_airport_code: string (nullable = true)\n",
      " |-- origin_city: string (nullable = true)\n",
      " |-- destination_city: string (nullable = true)\n",
      " |-- passengers: long (nullable = true)\n",
      " |-- seats: long (nullable = true)\n",
      " |-- flights: long (nullable = true)\n",
      " |-- distance: double (nullable = true)\n",
      " |-- origin_population: long (nullable = true)\n",
      " |-- destination_population: long (nullable = true)\n",
      " |-- flight_year: long (nullable = true)\n",
      " |-- flight_month: long (nullable = true)\n",
      " |-- __index_level_0__: long (nullable = true)\n",
      " |-- origin_airport_type: string (nullable = true)\n",
      " |-- origin_airport_name: string (nullable = true)\n",
      " |-- origin_airport_elevation_ft: double (nullable = true)\n",
      " |-- origin_airport_region: string (nullable = true)\n",
      " |-- origin_airport_municipality: string (nullable = true)\n",
      " |-- origin_airport_gps_code: string (nullable = true)\n",
      " |-- origin_airport_coordinates: string (nullable = true)\n",
      " |-- destination_airport_type: string (nullable = true)\n",
      " |-- destination_airport_name: string (nullable = true)\n",
      " |-- destination_airport_elevation_ft: double (nullable = true)\n",
      " |-- destination_airport_region: string (nullable = true)\n",
      " |-- destination_airport_municipality: string (nullable = true)\n",
      " |-- destination_airport_gps_code: string (nullable = true)\n",
      " |-- destination_airport_coordinates: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.table('flights_combined').printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+------------------------+---------------------+--------------------------+-----------------------+----+\n",
      "|                Name|IATA Code|Total Inbound Passengers|Total Inbound Flights|Average Inbound Passengers|Average Inbound Flights|Rank|\n",
      "+--------------------+---------+------------------------+---------------------+--------------------------+-----------------------+----+\n",
      "|Hartsfield Jackso...|      ATL|                35435896|               395729|         4097.109029945658|      45.75430685628396|   1|\n",
      "|Chicago O'Hare In...|      ORD|                26422032|               357181|        2799.5371900826444|     37.844988344988344|   2|\n",
      "|Dallas Fort Worth...|      DFW|                22835496|               270055|         4659.354417465824|       55.1020199959192|   3|\n",
      "|Los Angeles Inter...|      LAX|                19757561|               215359|         4029.688150112176|      43.92392412808485|   4|\n",
      "|McCarran Internat...|      LAS|                18315421|               163739|        4570.8562515597705|     40.863239331170455|   5|\n",
      "|Phoenix Sky Harbo...|      PHX|                17237993|               181608|        3827.2630994671404|     40.321492007104794|   6|\n",
      "|Charlotte Douglas...|      CLT|                15009641|               205650|         2420.519432349621|      33.16400580551524|   7|\n",
      "|George Bush Inter...|      IAH|                14854413|               213650|         2680.334355828221|     38.551064597618186|   8|\n",
      "|Orlando Internati...|      MCO|                14494016|               131676|         3884.753685339051|        35.292414902171|   9|\n",
      "|Detroit Metropoli...|      DTW|                14187841|               192531|        2482.1275367389785|      33.68282015395381|  10|\n",
      "+--------------------+---------+------------------------+---------------------+--------------------------+-----------------------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql3 = \"\"\"SELECT\n",
    "            origin_airport_name AS Name,\n",
    "            origin_airport_code AS `IATA Code`,\n",
    "            SUM(passengers) AS `Total Inbound Passengers`,\n",
    "            SUM(flights) AS `Total Inbound Flights`,\n",
    "            AVG(passengers) AS `Average Inbound Passengers`,\n",
    "            AVG(flights) AS `Average Inbound Flights`,\n",
    "            DENSE_RANK() OVER (ORDER BY SUM(passengers) DESC) AS Rank\n",
    "          FROM flights_combined\n",
    "          WHERE flight_year = 2008\n",
    "          GROUP BY origin_airport_name, origin_airport_code\"\"\"\n",
    "\n",
    "# Execute SQL Statement\n",
    "spark.sql(sql3).show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
